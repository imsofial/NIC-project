{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All the needed imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import snntorch as snn\n",
    "import snntorch.spikegen as spikegen\n",
    "import spikingjelly.activation_based.encoding as encoding\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**prepocess images**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Labels: ['glioma', 'meningioma', 'notumor', 'pituitary']\n"
     ]
    }
   ],
   "source": [
    "# Finding the data in the dictionary\n",
    "data_dir = pathlib.Path(\"..\") / \"brain-tumor-mri-dataset\"\n",
    "train_dir = data_dir / \"Training\"\n",
    "test_dir = data_dir / \"Testing\"\n",
    "\n",
    "\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.Grayscale(),  # Convert to grayscale\n",
    "    transforms.Resize((64, 64)),  # Resize for SNN, 64 for saving memory\n",
    "    transforms.RandomRotation(30),  # Rotation augmentation (randomly rotates the image up to Â±30 degrees)\n",
    "    transforms.RandomHorizontalFlip(), # Flips images horizontally (left to right)\n",
    "    transforms.ToTensor(),  # Convert to Tensor\n",
    "    transforms.Normalize((0.5,), (0.5,))  # Normalize, by reducing sharp spikes in activation\n",
    "])\n",
    "\n",
    "# Evaluate the model on real, unaltered images, so we dont do image augmantation.\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.Grayscale(),\n",
    "    transforms.Resize((64, 64)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "# Load images to train and test sets\n",
    "train_dataset = datasets.ImageFolder(root=train_dir, transform=transform_train)\n",
    "test_dataset = datasets.ImageFolder(root=test_dir, transform=transform_test)\n",
    "\n",
    "# Group multiple images into batches \n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Test correctness\n",
    "print(\"Class Labels:\", train_dataset.classes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**encoding images**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding transforms each pixel into a series of spikes:\n",
    "\n",
    "# Ensures your code can run on any machine\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Define timesteps (how many times an image generates spikes)\n",
    "# Instead of feeding the network one static image,\n",
    "# we feed 10 spike versions of it, to simulate passage of time\n",
    "timesteps = 10\n",
    "\n",
    "# rate-based encoding, it interprets the pixel intensity as a spike probability\n",
    "def encode_batch(batch, timesteps):\n",
    "    return spikegen.rate(batch, num_steps=timesteps).to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SNN MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This class uses spiking neurons, specifically Leaky Integrate-and-Fire(LIF),\n",
    "# to classify brain tumor MRI images into one of four classes\n",
    "class TumorSNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # 1st convolution layer:\n",
    "        # Input: 1 grayscale channel\n",
    "        # Output: 16 feature maps, using a 5x5 kernel\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=5, padding=2)\n",
    "        # Leaky Integrate-and-Fire neuron layer after conv1\n",
    "        self.lif1 = snn.Leaky(beta=0.9)\n",
    "\n",
    "        # 2nd convolution layer:\n",
    "        # It takes 16 input channels, outputs 32 feature maps\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=5, padding=2)\n",
    "        # Leaky Integrate-and-Fire neuron layer after conv2\n",
    "        self.lif2 = snn.Leaky(beta=0.9)\n",
    "\n",
    "        # Max pooling layer to reduce spatial dimensions by half\n",
    "        self.pool = nn.MaxPool2d(2) \n",
    "\n",
    "        # Fully connected layer:\n",
    "        # After 2 pools, input image size is 16x16\n",
    "        # With 32 feature maps, total flattened size = 32 * 16 * 16 = 8192\n",
    "        # Output: 4 classes (tumor types)\n",
    "        self.fc = nn.Linear(32 * 16 * 16, 4)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Creates an initial state of that membrane potential, which is required to:\n",
    "        # - Keep track of voltage inside the neuron\n",
    "        # - Allow the model to \"remember\" signals from previous time steps\n",
    "        # for 2 LIF layers\n",
    "        mem1 = self.lif1.init_leaky()\n",
    "        mem2 = self.lif2.init_leaky()\n",
    "\n",
    "        # To sum up the outputs from each timestep, because:\n",
    "        # x has shape [timesteps, batch, channels, height, width]\n",
    "        spk_sum = 0\n",
    "        for step in range(x.size(0)):  # timesteps\n",
    "            cur = x[step] # Get image spike frame at current timestep\n",
    "\n",
    "            # First conv. + pool layer\n",
    "            cur = self.pool(self.conv1(cur))\n",
    "            spk1, mem1 = self.lif1(cur, mem1) # LIF neuron returns (spike, membrane)\n",
    "\n",
    "            # Second conv + pool layer\n",
    "            cur = self.pool(self.conv2(spk1))\n",
    "            spk2, mem2 = self.lif2(cur, mem2) # LIF neuron returns (spike, membrane)\n",
    "\n",
    "            # Flatten the output for the fully connected layer, \n",
    "            # turning a 3D tensor (channels, height, width) into a 1D vector\n",
    "            # so it can be passed into a fully connected (dense) layer ????\n",
    "            flat = spk2.view(spk2.size(0), -1)\n",
    "\n",
    "            # Final linear classification layer\n",
    "            out = self.fc(flat)\n",
    "\n",
    "            spk_sum += out\n",
    "\n",
    "        # Return the average output across all timesteps\n",
    "        return spk_sum / x.size(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**initialize the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TumorSNN().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Training function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Loss function\n",
    "# It compares predicted class scores to true class labels\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Define the optimizer\n",
    "# We use Adam for efficient optimizing that adjusts learning rates dynamically\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training function\n",
    "def train_snn(model, loader, epochs=5):\n",
    "    model.train() # set the model into training mode\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0 # Keep track of total loss in this epoch\n",
    "\n",
    "        # Loop over all batches in the dataset\n",
    "        for imgs, labels in loader:\n",
    "\n",
    "            # Move data to GPU (or CPU), depending on device\n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "\n",
    "            # Encode static images into spike trains over time\n",
    "            spikes = encode_batch(imgs, timesteps)\n",
    "\n",
    "            # Reset gradients before backprop\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Get predictions from the SNN\n",
    "            outputs = model(spikes)\n",
    "\n",
    "            # Compute loss between predictions and true labels\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Compute gradients, backpropagation\n",
    "            loss.backward()\n",
    "            \n",
    "            # Optimizer step, update model weights\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{epochs} | Loss: {total_loss/len(loader):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Testing Function (Full Evaluation)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_snn(model, loader):\n",
    "    model.eval() # set the model to evaluation mode\n",
    "    y_true, y_pred = [], []\n",
    "\n",
    "    # Disables gradient calculations (saves memory and speeds up inference)\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in loader:\n",
    "            # Move data to the same device as the model\n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "            # Encode static images into spiking format\n",
    "            spikes = encode_batch(imgs, timesteps)\n",
    "            # Run the forward pass to get predictions\n",
    "            outputs = model(spikes)\n",
    "            # Get predicted class index (0-3) with highest score per sample\n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "\n",
    "            # Saves results for evaluation, move from GPU to CPU.\n",
    "            y_true.extend(labels.cpu().numpy())\n",
    "            y_pred.extend(preds.cpu().numpy())\n",
    "\n",
    "    print(f\"Accuracy: {accuracy_score(y_true, y_pred) * 100:.2f}%\")\n",
    "    print(f\"Precision: {precision_score(y_true, y_pred, average='weighted') * 100:.2f}%\")\n",
    "    print(f\"Recall: {recall_score(y_true, y_pred, average='weighted') * 100:.2f}%\")\n",
    "    print(f\"F1 Score: {f1_score(y_true, y_pred, average='weighted') * 100:.2f}%\")\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_true, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Run the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5 | Loss: 1.0248\n",
      "Epoch 2/5 | Loss: 0.8582\n",
      "Epoch 3/5 | Loss: 0.7977\n",
      "Epoch 4/5 | Loss: 0.7667\n",
      "Epoch 5/5 | Loss: 0.7471\n",
      "Accuracy: 69.26%\n",
      "Precision: 69.46%\n",
      "Recall: 69.26%\n",
      "F1 Score: 69.22%\n",
      "Confusion Matrix:\n",
      "[[216  59   1  24]\n",
      " [ 51 162  66  27]\n",
      " [ 38  40 301  26]\n",
      " [ 43  17  11 229]]\n"
     ]
    }
   ],
   "source": [
    "train_snn(model, train_loader, epochs=5)\n",
    "test_snn(model, test_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
